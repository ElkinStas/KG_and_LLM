{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import hashlib\n",
    "from datasets import load_dataset\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/workspace/itmo_courses/разные проекты\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "strory = '''\n",
    "The story begins with two unnamed officers of unknown rank sitting in the guardroom for unspecified crimes. Due to boredom, one of the officers, subsequently referred to as \"Crazy,\" starts telling his life stories to the other officer, referred to as \"Brother.\" Throughout his narrative, the level of madness in Crazy's tales escalates. He recounts incidents such as an attempt to humiliate a fellow soldier by defecating in his boot during mandatory service, consuming feces, and his first sexual experience (\"Had a few shots of 'Triple Seven' with some crazy chick, and then we messed around\").\n",
    "Initially, Brother finds these stories amusing, but in the confined space with such an \"interesting\" cellmate, he becomes increasingly uncomfortable. He asks Crazy to \"shut up,\" but Crazy refuses. In response, Brother reports him to the authorities. Later, Crazy notices a lot of flies in their cell. In an attempt to rid Brother of the flies, Crazy suggests defecating on the floor, hoping the flies will gather, and he can kill them. However, Brother beats him again.\n",
    "Crazy groans in pain, and the noise attracts the attention of the Guard, a vile and weak man with authority over cellmates, who takes Brother away for \"work.\" The so-called \"work\" involves cleaning a dirty toilet using a dining fork. The Guard explicitly instructs Brother to \"clean the crap.\" Brother, either genuinely not understanding the task or pretending to be repulsed, sits and curses the guard. The Guard returns to the toilet, efficiently, if not \"virtuosically,\" scraping it with the fork to demonstrate the proper technique. However, Brother stubbornly refuses to comply, openly declaring to the returning Guard that he won't clean. Furious, the Guard drives Brother out of the latrine.\n",
    "When Brother returns to the cell, Crazy decides to sing him a song about the \"green elephant,\" a nonsensical and childlike tune inappropriate for their setting. After their conversation, Brother goes to sleep, while Crazy prepares a \"breakfast\" for his friend – defecating in a bowl, smearing feces on the floor and his belly, and even sniffing and eating it. The next morning, Crazy brings Brother a so-called \"sweet bread\" (referring to his own excrement) in the only clean bowl in the cell.\n",
    "This becomes the last straw for Brother, who, with loud cries, pleads to \"take this shit-eater away.\" However, he himself goes back to clean the toilet. While Brother learns the basics of this \"art,\" Captain, the head of the guardroom, enters Crazy's cell and starts narrating a story, heavily seasoned with profanity (and factual errors), about the Japanese attack on Pearl Harbor. Although Crazy struggles to comprehend this \"classic\" tale, the Captain imparts his intended message. After the lecture, the Guard, following the Captain's orders, beats Crazy. For many readers of 2ch and YouTube, the story concludes here, as the subsequent events are too explicit and bloody to describe. Nevertheless, the story must be completed.\n",
    "Following further Captain-induced torment in the \"hole,\" Brother loses his sanity entirely, kills the Captain, and then slashes his own wrists. The Guard, now donning the Captain's uniform, believes himself to be a colonel and aspires to \"go to the Officers' Club\" but ultimately decides to hang himself as well. Meanwhile, Crazy remains alone in the \"hole,\" singing about the \"Green Elephant\" amidst intestines and blood. Instead of Brother's corpse, he hallucinates his own mother, engaging in a conversation with her.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_data, test_data = load_dataset(\"suolyer/pile_wikipedia\", split=['validation', 'test'])\n",
    "\n",
    "data = []\n",
    "#random_rows = random.sample(range(len(test_data)), 10)\n",
    "build_data = toker = strory.split('.')\n",
    "\n",
    "m = hashlib.md5()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def bert_len(text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "def create_chunk_dataset(content):\n",
    "    m.update(content.encode('utf-8'))\n",
    "    uid = m.hexdigest()[:12]\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "          chunk_size = 400,\n",
    "          chunk_overlap  = 40,\n",
    "          length_function = bert_len,\n",
    "          separators=['\\n\\n', '\\n', ' ', ''],\n",
    "      )\n",
    "    chunks = text_splitter.split_text(content)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "          data.append({\n",
    "              'id': f'{uid}-{i}',\n",
    "              'text': chunk\n",
    "          })\n",
    "\n",
    "for dt in build_data:\n",
    "    create_chunk_dataset(dt)\n",
    "\n",
    "filename = 'rebel_llamaindex/green_elephant_chunks.jsonl'\n",
    "# save\n",
    "with open(filename, 'w') as outfile:\n",
    "    for x in data:\n",
    "        outfile.write(json.dumps(x) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(text):\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "    return triplets\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b9f0fc82234fd1bd8c7ee0724d594a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_kwargs = {\n",
    "    \"max_length\": 256,\n",
    "    \"length_penalty\": 0,\n",
    "    \"num_beams\": 3,\n",
    "    \"num_return_sequences\": 1,\n",
    "}\n",
    "\n",
    "triples = []\n",
    "\n",
    "def generate_triples(texts):\n",
    "    model_inputs = tokenizer(texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    generated_tokens = model.generate(\n",
    "      model_inputs[\"input_ids\"].to(model.device),\n",
    "      attention_mask=model_inputs[\"attention_mask\"].to(model.device),\n",
    "      **gen_kwargs\n",
    "   )\n",
    "    decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "    for idx, sentence in enumerate(decoded_preds):\n",
    "        et = extract_triplets(sentence)\n",
    "        for t in et:\n",
    "            triples.append((t['head'], t['type'], t['tail']))\n",
    "\n",
    "for i in tqdm(range(0, len(data), 2)):\n",
    "    try:\n",
    "        texts = [data[i]['text'], data[i+1]['text']]\n",
    "    except:\n",
    "        texts = [data[i]['text']]\n",
    "    generate_triples(texts)\n",
    "\n",
    "distinct_triples = list(set(triples))\n",
    "\n",
    "# save\n",
    "with open('rebel_triples.json', 'w') as file:\n",
    "    json.dump(distinct_triples, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Captain', 'characters', 'Crazy'),\n",
       " ('2ch', 'different from', 'YouTube'),\n",
       " ('intestines', 'has part', 'blood')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_triples[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distinct_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    KnowledgeGraphIndex,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    SimpleDirectoryReader,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your_key'\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ")  \n",
    "\n",
    "from llama_index import (\n",
    "    KnowledgeGraphIndex,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.graph_stores import NebulaGraphStore\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores import SimpleGraphStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.graph_stores import SimpleGraphStore\n",
    "\n",
    "graph_store = SimpleGraphStore()\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "documents = SimpleDirectoryReader(\"rebel_llamaindex/\").load_data()\n",
    "\n",
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    max_triplets_per_chunk=2,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "triplet_extractor = pipeline('text2text-generation', model='Babelscape/rebel-large', tokenizer='Babelscape/rebel-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_name = \"llamaindex\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\"relationship\"] \n",
    "tags = [\"entity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebel_kg_index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    kg_triplet_extract_fn=extract_triplets,\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=5,\n",
    "    service_context=service_context,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    include_embeddings=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
