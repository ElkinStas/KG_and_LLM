KG_and_LLM
Исследовательский проект по исследованию работы графов знаний и использованию их совместно с языковыми моделями.
Рост популярности LLM породил новые сферы связанные с работой и исследованиями вокруг них. Одной из таких сфер является (RAG), или Retrieval Augmented Generation.
RAG позволяет подключать к моделям память, и дает им возможность работать с новыми фактами не затронутыми при обучении. 
На текущий момент RAG'и только начинают свое развитие, и одним из перспективных баз для RAG'а являются графы знаний. 
Наше исследование затронет то, как мы можем совмещать LLM и KG для построения перспективного RAG.

Изначально нашей задумкой было строить RAG на базе графов знаний для строительной документации, но в итоге увидив перспективы наша задача перенеслась в более исследовательскую плоскость, и мы начали подробный обзор литературы и научных ресурсов связанных с постройкой графов знаний и RAG.

Для начала мы проанализировали большое количество научных статей связанных с постройкой графа знаний.

| Link                                                                                   | Name                                                                                           | Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
|----------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Springer Link](https://link.springer.com/chapter/10.1007/978-3-031-48421-6_23)        | [BEAR on GitHub](https://github.com/HTXone/BEAR)                                               | Requires payment, but interesting examples are available on GitHub.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| [Arxiv Paper](https://arxiv.org/pdf/2305.13168.pdf)                                    | LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities | A brief overview of the tasks where LLMs currently excel and where they do not. They are good at reasoning and worse at construction. Suggests an agent-based approach to graph construction. The method is somewhat vague.                                                                                                                                                                                                                                                                                                                                                                                 |
| [Arxiv Paper](https://arxiv.org/pdf/2008.08995.pdf)                                    | AutoKG: Constructing Virtual Knowledge Graphs from Unstructured Documents for Question Answering   | An older work on graph construction pre-GPT on BERT. The method is interesting and worth considering. Briefly, it's a three-step process: 1. OpenEI for creating triplets, 2. Encoding with BERT, 3. Entity linking (though unclear how).                                                                                                                                                                                                                                                                                                                                                                    |
| [Arxiv Paper](https://arxiv.org/abs/2308.02357)                                        | Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text                | Proposes a benchmark for the task of knowledge graph generation. A very recent article with a new benchmark.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| [Arxiv Paper](https://arxiv.org/pdf/2307.01128.pdf)                                    | ITERATIVE ZERO-SHOT LLM PROMPTING FOR KNOWLEDGE GRAPH CONSTRUCTION                              | Proposes an iterative LLM prompting-based pipeline for automatically generating KGs without human effort. It introduces well-formed LLM prompts for each stage of the process and achieves impressive accuracy results.                                                                                                                                                                                                                                                                                                                                                                                      |
| [PLOS One Article](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0292903) |                                                                                                | Similar to the previous article. If we decide to build graphs, this article should be examined carefully. Essentially, it proposes the same agent-based approach with good accuracy parameters for their specific task.                                                                                                                                                                                                                                                                                                                                                                                      |
| [FCST Article](http://fcst.ceaj.org/EN/Y2023/V17/I10/2377)                             |                                                                                                | Chinese language article. From images, it appears to involve multi-layered prompts.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| [Arxiv Paper](https://arxiv.org/pdf/2306.08302.pdf)                                    | Unifying Large Language Models and Knowledge Graphs: A Roadmap                                  | An excellent overview of current developments. Dedicated subsections for each process of interest.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| [Arxiv Paper](https://arxiv.org/pdf/2305.12392.pdf)                                    | PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs   | Uses a model with a verifier module for graph construction. Briefly, they trained a small transformer on correct/incorrect responses and generate iteratively with it.                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| [Arxiv Paper](https://arxiv.org/abs/2206.14268)                                        | BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models    | Constructs graphs using prompts and a trained BERT. Achieves up to 70% accuracy in some cases.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| [Arxiv Paper](https://arxiv.org/pdf/2304.09048v1.pdf)                                  | CodeKGC: Code Language Model for Generative Knowledge Graph Construction                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| [Arxiv Paper](https://arxiv.org/pdf/2310.17238v1.pdf)                                  | Joint Entity and Relation Extraction with Span Pruning and Hypergraph Neural Networks            | Describes an ERE model based on Packed Levitated Marker. The code didn't work well, so it's challenging to verify the method's effectiveness.                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| [Arxiv Paper](https://arxiv.org/pdf/2109.06067.pdf)                                    | Packed Levitated Marker for Entity and Relation Extraction                                      | Describes the Packed Levitated Marker method for ERE data labeling. The code is functional, and metrics are confirmed. It's difficult to say whether it should be used in our work.                                                                                                                                                                                                                                                                                                                                                                                                                        |
| [GitHub - REBEL](https://github.com/Babelscape/rebel/blob/main/docs/EMNLP_2021_REBEL__Camera_Ready_.pdf) | REBEL: Relation Extraction By End-to-end Language generation                                   | REBEL, a seq2seq model based on BART, performs end-to-end relation extraction for over 200 different relation types. It works excellently and is currently in use.                                                                                                                                                                                                                                                                                                                                                                                                                                           |

После 2х месяцев изучения графов знаний, и научных статей мы пришли к выводу, что будет ценно построить RAG на графах знаний. Сравнить его по сравнению с обычным RAG на векторной базе, и попробовать обернуть это все в библиотеку либо научную статью.

Из актуальных задач:
1. Генерация и сборка датасета для RAG
  К сожалению до сих пор не собран достаточно приемлимый датасет для RAG, поэтому нам необходимо будет разработать его самим.
2. Определение метрик для RAG
3. 

