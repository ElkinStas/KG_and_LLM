KG_and_LLM
Исследовательский проект по исследованию работы графов знаний и использованию их совместно с языковыми моделями.
Рост популярности LLM породил новые сферы связанные с работой и исследованиями вокруг них. Одной из таких сфер является (RAG), или Retrieval Augmented Generation.
RAG позволяет подключать к моделям память, и дает им возможность работать с новыми фактами не затронутыми при обучении. 
На текущий момент RAG'и только начинают свое развитие, и одним из перспективных баз для RAG'а являются графы знаний. 
Наше исследование затронет то, как мы можем совмещать LLM и KG для построения перспективного RAG.

Изначально нашей задумкой было строить RAG на базе графов знаний для строительной документации, но в итоге увидив перспективы наша задача перенеслась в более исследовательскую плоскость, и мы начали подробный обзор литературы и научных ресурсов связанных с постройкой графов знаний и RAG.

Для начала мы проанализировали большое количество научных статей связанных с постройкой графа знаний.
| Link                                                                      	| Name                                                                                              	| Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              	|
|---------------------------------------------------------------------------	|---------------------------------------------------------------------------------------------------	|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|
| https://link.springer.com/chapter/10.1007/978-3-031-48421-6_23            	| https://github.com/HTXone/BEAR                                                                    	| Стоит денег, но на гх есть примеры интересные                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        	|
| https://arxiv.org/pdf/2305.13168.pdf                                      	| LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities 	| Небольшой обзор в каких задачах llm’ки сейчас справляются а в каких нет. Если коротко, то они неплохо справляются с reasoning, и хуже с construction. Предлагают агентный подход к постройке графа. Достаточно размыто, как именно они это делали.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   	|
| https://arxiv.org/pdf/2008.08995.pdf                                      	| AutoKG: Constructing Virtual Knowledge Graphsfrom Unstructured Documents for Question Answering   	| Старая работа по постройке графов, но это до gpt на берте. Способ интересный. Можно рассмотреть. Если коротко, то трехступенчатый процесс:1. OpenEI для создания триплетов2. Энкодинг с помощью берта3. Entity linking, но я не понял как.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           	|
| https://arxiv.org/abs/2308.02357                                          	| Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text                	| Предложили бенчмарк для нашей задачи. Очень свежая статья с бенчмарком.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              	|
| https://arxiv.org/pdf/2307.01128.pdf                                      	| ITERATIVE ZERO-SHOT LLM PROMPTING FOR KNOWLEDGEGRAPH CONSTRUCTION                                 	| we propose an iterative LLM prompting-based pipeline for automatically generating KGs. Let us remark thatthere is no need for any human effort;• we propose a sequence of proper, well-formed LLM prompts for each stage of the process. The devisedprompts are able to:◦ identify relevant entities and extract their descriptions and type;◦ identify meaningful relationships and their descriptions;◦ given the previous components, identify relevant triplets;◦ provide domain-specific triplets, even if no information about the domain is given as input;◦ resolving entities and predicates in an automated and reliable way, without relying on any third-partyresources.• we propose a “zero-shot” approach, as all the devised prompts do not need any examples or external KBs forinferring the related information.Сделали что-то вроде агентного подхода для построения KG но без агентного подхода. Неплохие по точности результаты 	|
| https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0292903 	|                                                                                                   	| Похоже на предыдущую статью. Если решим все таки строить графы надо будет вдумчиво взглянуть в статью. По сути они предлагают тот же агентный подход. Неплохие параметры по точности в их специфической задачЕ.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      	|
|                                                                           	| http://fcst.ceaj.org/EN/Y2023/V17/I10/2377                                                        	| Китайский язык. Из картинок виднеются какие-то многослойные промпты.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 	|
| https://arxiv.org/pdf/2306.08302.pdf                                      	| Unifying Large Language Models andKnowledge Graphs: A Roadmap                                     	| Очень неплохой обзор того, что сейчас происходит. Отдельно посвящены подразделы каждому процессу который нас интересует.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             	|
| https://arxiv.org/pdf/2305.12392.pdf                                      	| PiVe: Prompting with Iterative VerificationImproving Graph-based Generative Capability of LLMs    	| Используют модель с verifier модулем для постройки графов. Если коротко, то натренировали крошечный трансформер на ответы correct/incorrect, и последовательно генерируют с помощью него.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	|
| https://arxiv.org/abs/2206.14268                                          	| BertNet: Harvesting Knowledge Graphs with Arbitrary Relationsfrom Pretrained Language Models      	| Строили графы с помощью промптов и натренированной BERT. 70 - точность в некоторых случаях.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          	|
| https://arxiv.org/pdf/2304.09048v1.pdf                                    	| CodeKGC: Code Language Model for GenerativeKnowledge Graph Construction                           	|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      	|
| https://arxiv.org/pdf/2310.17238v1.pdf					| Joint Entity and Relation Extraction with Span Pruning and Hypergraph Neural Networks                     | Описана модел извелечения именных сущностей и связей (ERE) на основе Packed Levitated Marker. Код не взлетел, сложно проверить работоспособность метода |
| https://arxiv.org/pdf/2109.06067.pdf					| Packed Levitated Marker for Entity and Relation Extraction							| Описан способ разметки данных для задачи ERE - Packed Levitated Marker. Код рабочий, метрики бьются. Сложно сказать, стоит ли брать его в работу |
| https://github.com/Babelscape/rebel/blob/main/docs/EMNLP_2021_REBEL__Camera_Ready_.pdf | REBEL: Relation Extraction By End-to-end Language generation |REBEL, модель seq2seq, основанную на BART, выполняющую полностью конечное извлечение отношений для более чем 200 различных типов отношений. Работает отлично и взята в работу в данный момент |


| Link                                                                                   | Name                                                                                           | Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
|----------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Springer Link](https://link.springer.com/chapter/10.1007/978-3-031-48421-6_23)        | [BEAR on GitHub](https://github.com/HTXone/BEAR)                                               | Requires payment, but interesting examples are available on GitHub.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| [Arxiv Paper](https://arxiv.org/pdf/2305.13168.pdf)                                    | LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities | A brief overview of the tasks where LLMs currently excel and where they do not. They are good at reasoning and worse at construction. Suggests an agent-based approach to graph construction. The method is somewhat vague.                                                                                                                                                                                                                                                                                                                                                                                 |
| [Arxiv Paper](https://arxiv.org/pdf/2008.08995.pdf)                                    | AutoKG: Constructing Virtual Knowledge Graphs from Unstructured Documents for Question Answering   | An older work on graph construction pre-GPT on BERT. The method is interesting and worth considering. Briefly, it's a three-step process: 1. OpenEI for creating triplets, 2. Encoding with BERT, 3. Entity linking (though unclear how).                                                                                                                                                                                                                                                                                                                                                                    |
| [Arxiv Paper](https://arxiv.org/abs/2308.02357)                                        | Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text                | Proposes a benchmark for the task of knowledge graph generation. A very recent article with a new benchmark.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| [Arxiv Paper](https://arxiv.org/pdf/2307.01128.pdf)                                    | ITERATIVE ZERO-SHOT LLM PROMPTING FOR KNOWLEDGE GRAPH CONSTRUCTION                              | Proposes an iterative LLM prompting-based pipeline for automatically generating KGs without human effort. It introduces well-formed LLM prompts for each stage of the process and achieves impressive accuracy results.                                                                                                                                                                                                                                                                                                                                                                                      |
| [PLOS One Article](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0292903) |                                                                                                | Similar to the previous article. If we decide to build graphs, this article should be examined carefully. Essentially, it proposes the same agent-based approach with good accuracy parameters for their specific task.                                                                                                                                                                                                                                                                                                                                                                                      |
| [FCST Article](http://fcst.ceaj.org/EN/Y2023/V17/I10/2377)                             |                                                                                                | Chinese language article. From images, it appears to involve multi-layered prompts.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| [Arxiv Paper](https://arxiv.org/pdf/2306.08302.pdf)                                    | Unifying Large Language Models and Knowledge Graphs: A Roadmap                                  | An excellent overview of current developments. Dedicated subsections for each process of interest.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| [Arxiv Paper](https://arxiv.org/pdf/2305.12392.pdf)                                    | PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs   | Uses a model with a verifier module for graph construction. Briefly, they trained a small transformer on correct/incorrect responses and generate iteratively with it.                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| [Arxiv Paper](https://arxiv.org/abs/2206.14268)                                        | BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models    | Constructs graphs using prompts and a trained BERT. Achieves up to 70% accuracy in some cases.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| [Arxiv Paper](https://arxiv.org/pdf/2304.09048v1.pdf)                                  | CodeKGC: Code Language Model for Generative Knowledge Graph Construction                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| [Arxiv Paper](https://arxiv.org/pdf/2310.17238v1.pdf)                                  | Joint Entity and Relation Extraction with Span Pruning and Hypergraph Neural Networks            | Describes an ERE model based on Packed Levitated Marker. The code didn't work well, so it's challenging to verify the method's effectiveness.                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| [Arxiv Paper](https://arxiv.org/pdf/2109.06067.pdf)                                    | Packed Levitated Marker for Entity and Relation Extraction                                      | Describes the Packed Levitated Marker method for ERE data labeling. The code is functional, and metrics are confirmed. It's difficult to say whether it should be used in our work.                                                                                                                                                                                                                                                                                                                                                                                                                        |
| [GitHub - REBEL](https://github.com/Babelscape/rebel/blob/main/docs/EMNLP_2021_REBEL__Camera_Ready_.pdf) | REBEL: Relation Extraction By End-to-end Language generation                                   | REBEL, a seq2seq model based on BART, performs end-to-end relation extraction for over 200 different relation types. It works excellently and is currently in use.                                                                                                                                                                                                                                                                                                                                                                                                                                           |



